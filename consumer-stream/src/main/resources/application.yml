server:
  servlet:
    context-path: /
  port: 8080
logging:
  level:
    root: INFO
    com.xabe.spring.cloud.stream: DEBUG
    org.springframework.cloud.stream: INFO
    org.springframework.retry: DEBUG
    org.springframework.core.log: DEBUG

spring:
  main:
    allow-bean-definition-overriding: true
  application:
    name: consumer
  cloud:
    schemaRegistryClient:
      enabled: true
    stream:
      schema:
        avro:
          subjectNamingStrategy: com.xabe.spring.cloud.stream.consumer.infrastructure.config.SubjectNamingStrategy
          dynamicSchemaGenerationEnabled: true
      schemaRegistryClient:
        endpoint: http://localhost:8081
        cached: true
      kafka:
        bindings:
          consumer-car-in:
            consumer:
              destination-is-pattern: true
              idleEventInterval: ${consumer.idleEventInterval:30000}
          consumer-car-dlq-in:
            consumer:
              destination-is-pattern: true
              idleEventInterval: ${consumer.idleEventInterval:30000}
          producer-car-dlq-out:
            producer:
              messageKeyExpression: headers['partitionKey']
        binder:
          health-timeout: 60
      binders:
        kafka-pipe:
          type: kafka
          environment:
            spring.main.sources: com.xabe.spring.cloud.stream.consumer.infrastructure.messaging.ConsumerResumeListener
            spring.cloud.stream.kafka.binder:
              configuration:
                compression.type: gzip
              producer-properties:
                key.serializer: org.apache.kafka.common.serialization.StringSerializer
                value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
                schema.registry.url: http://localhost:8081
                enable.idempotence: true
                retries: 10
                request.timeout.ms: 30000
                client.id: producer
                max.block.ms: 1000
                linger.ms: 20
                batch.size: 32768
                use.latest.version: true
              consumer-properties:
                key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
                value.deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
                schema.registry.url: http://localhost:8081
                request.timeout.ms: 30000
                specific.avro.reader: true
                client.id: consumer
                use.latest.version: true
              autoAddPartitions: true
              autoCreateTopics: true
              minPartitionCount: 3
              defaultBrokerPort: 9092
              requiredAcks: all
              brokers:
                - localhost
      bindings:
        consumer-car-in:
          binder: kafka-pipe
          consumer:
            autoCommitOffset: true
            partitioned: true
            startOffset: ${consumer.startOffset:latest}
            concurrency: ${consumer.concurrency:3}
            max-attemps: ${consumer.maxattemps:3}
          group: ${consumer.group:car}
          destination: ${consumer.car.topic:car.v1}
          contentType: application/*+avro
        consumer-car-dlq-in:
          binder: kafka-pipe
          consumer:
            autoCommitOffset: true
            startOffset: ${consumer.startOffset:latest}
            concurrency: ${consumer.concurrency:3}
            max-attemps: ${consumer.maxattemps:3}
          group: ${consumer.group:carDlq}
          destination: ${consumer.car-dlq.topic:car.dlq.v1}
          contentType: application/*+avro
        producer-car-dlq-out:
          binder: kafka-pipe
          destination: ${producer.car-dlq.topic:car.dlq.v1}
          content-type: application/*+avro
          producer:
            partitionCount: ${producer.partitioncount:3}
            useNativeEncoding: true